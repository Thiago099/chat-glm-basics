{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No compiled kernel found.\n",
      "Compiling kernels : C:\\Users\\Thiago\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\6498797e7951d5b8fe55f34e35172b178533656a\\quantization_kernels_parallel.c\n",
      "Compiling gcc -O3 -fPIC -pthread -fopenmp -std=c99 C:\\Users\\Thiago\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\6498797e7951d5b8fe55f34e35172b178533656a\\quantization_kernels_parallel.c -shared -o C:\\Users\\Thiago\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\6498797e7951d5b8fe55f34e35172b178533656a\\quantization_kernels_parallel.so\n",
      "Compile default cpu kernel failed, using default cpu kernel code.\n",
      "Compiling gcc -O3 -fPIC -std=c99 C:\\Users\\Thiago\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\6498797e7951d5b8fe55f34e35172b178533656a\\quantization_kernels.c -shared -o C:\\Users\\Thiago\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\6498797e7951d5b8fe55f34e35172b178533656a\\quantization_kernels.so\n",
      "Compile default cpu kernel failed.\n",
      "Failed to load kernel.\n",
      "Cannot load cpu kernel, don't use quantized model on cpu.\n",
      "Using quantization cache\n",
      "Applying quantization to glm layers\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True).half().cuda()\n",
    "model = model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you touch something hot, such as a stove or a sunbeam, you can experience various effects. The most common ones are:\n",
      "\n",
      "1.  烧伤： The hot object will cause a skin or muscle to be烧伤， if not immediately cool it down with water or ice, the skin can become raw or even kill the user.\n",
      "\n",
      "2.  Stovetop explosion: If the hot object is too hot and the air is not混合 properly, it can cause an explosion, also it can cause fire.\n",
      "\n",
      "3.  化学灼伤： Some objects, such as chemical torches or thermionic devices, can cause chemical灼伤， which can be serious.\n",
      "\n",
      "4.  烫焦： If the hot object is too hot and it touch the ground, the object can be烫焦 (burned to a crisp) and it can also cause fire.\n",
      "\n",
      "It is important to always cool the hot object down and to make sure that the user is not holding the hot object with the wrong hand, that could also be烧伤.\n",
      "I am an AI language model, known as ChatGLM. I am built to assist and communicate with users, answer their questions, and provide information to them. I am based on the GLM model developed by Knowledge Engineering Group, Tsinghua University and Zhipu.AI.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"what happen if you touch something\", history=[])\n",
    "print(response)\n",
    "response, history = model.chat(tokenizer, \"who are you\", history=history)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
